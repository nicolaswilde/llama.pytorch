# llama.pytorch
Use PyTorch! If you find llama.cpp is too complicated to customize.

# Usage

- you have to `export HF_TOKEN=your_huggingface_token` before running the code.
- you have to install `transformers`, `torch`, `gguf` before running the code.
- you have to download the gguf model from huggingface, and modify the `model_path` in the code.
- finally, run the code with `python model.py`.